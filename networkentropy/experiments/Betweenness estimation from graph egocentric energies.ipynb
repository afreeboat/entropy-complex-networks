{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "# Correlation of vertex betweenness with graph energy of vertex egocentric network\n",
    "\n",
    "In this experiment we are considering the measure of energy dispersion and its correlation to betweeness of vertices. There are multiple graph energies proposed in the literature, but our primary interest lies in Graph, Laplacian and Randić energies. Within the experiment we calculate the energy of each vertex by means of their ego-network. Then we compare how betweenes of vertices is correlated with the energy of their egocentric networks.\n",
    "\n",
    "Our second experiment aims at using machine learning to predict the betweenness of a vertex from only the local information contained in the egocentric network of that vertex. Computing of betweenness requires a very costly computation of all shortest paths in the network. Our approach allows to estimate betweennes using only local information.\n",
    "\n",
    "Finally, in our third experiment, we perform transfer learning, training a model for predicting betweenness on one network, and using this model to predict betweenness of vertices in other networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph energy\n",
    "\n",
    "Graph energy of a graph is defined as $E_G(G) = \\sum\\limits_{i=1}^n |\\mu_i|$, where $\\mu_1, \\ldots, \\mu_n$ are the eigenvalues of the adjacency matrix $M_A$ (also known as the *spectrum* of the graph).\n",
    "\n",
    "## Randić energy\n",
    "\n",
    "Randić matrix of the graph $G=\\left<V, E\\right>$ is defined as:\n",
    "\n",
    "$$\n",
    "M_R(i,j)=\n",
    "\\begin{cases}\n",
    "0 & \\mathit{if} & i=j\\\\\n",
    "\\frac{1}{\\sqrt{d_i d_j}} & \\mathit{if} & (i,j) \\in E\\\\\n",
    "0 & \\mathit{if} & (i,j) \\notin E\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Randić energy of a graph is defined as $E_R(G) = \\sum\\limits_{i=1}^n |\\rho_i|$, where $\\rho_1, \\ldots, \\rho_n$ are the eigenvalues of the Randić matrix $M_R$.\n",
    "\n",
    "## Laplacian energy\n",
    "\n",
    "Laplacian matrix of the graph $G=\\left<V, E\\right>$ is defined as:\n",
    "\n",
    "$$\n",
    "M_L(i,j)=\n",
    "\\begin{cases}\n",
    "d_i & \\mathit{if} & i=j\\\\\n",
    "-1 & \\mathit{if} & (i,j) \\in E\\\\\n",
    "0 & \\mathit{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Laplacian energy of a graph is defined as $E_L(G) =  \\sum\\limits_{i=1}^n |\\lambda_i - \\frac{2m}{n}|$, where $\\lambda_1, \\ldots, \\lambda_n$ are the eigenvalues of the Laplacian matrix $M_L$, $n$ is the number of vertices and $m$ is the number of edges in the graph $G$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from ggplot import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy, scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.preprocessing\n",
    "import logging\n",
    "import requests\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import network_energy as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"\n",
    "    Divide a list of vertices `lst` into chunks consisting of `n` vertices\n",
    "    \n",
    "    Tests:\n",
    "    >>> list(chunks([1,2,3,4,5,6], 2))\n",
    "    [(1, 2), (3, 4), (5, 6)]\n",
    "\n",
    "    >>> list(chunks([1,2,3,4,5,6], 4))\n",
    "    [(1, 2, 3, 4), (5, 6)]\n",
    "\n",
    "    >>> list(chunks([], 2))\n",
    "    []\n",
    "\n",
    "    \"\"\"\n",
    "    _lst = iter(lst)\n",
    "    while 1:\n",
    "        x = tuple(itertools.islice(_lst, n))\n",
    "        if not x:\n",
    "            return\n",
    "        yield x\n",
    "        \n",
    "def normalize_df_column(df_column):\n",
    "    \"\"\"\n",
    "    Normalize a dataframe column to the range [0,1]\n",
    "    \n",
    "    Tests:\n",
    "    >>> normalize_df_column(pd.Series([1,2,3,4,5]))\n",
    "    array([[0.  ],\n",
    "           [0.25],\n",
    "           [0.5 ],\n",
    "           [0.75],\n",
    "           [1.  ]])\n",
    "    \"\"\"\n",
    "    x = df_column.values.astype(float)\n",
    "    min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x.reshape(-1,1))\n",
    "    \n",
    "    return x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import doctest\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix energies for various topologies of small egocentric networks\n",
    "\n",
    "Firstly, let us examine the relationship between the topology of a small egocentric network and its energies. We generate five different egocentric networks representing possible small scale configurations and compute all three types of matrix energies. The results are somehow surprising, graph energy tends to correlate with the degree of connectivity of the egocentric network, Randic energy remains practically constant, and Laplacian energy behaves unpredictably, receiving the maximum value for a custom topology. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_custom = nx.star_graph(n=5)\n",
    "g_custom.add_edge(1,2)\n",
    "g_custom.add_edge(4,5)\n",
    "\n",
    "graphs = [\n",
    "    {'name': 'path', 'graph': nx.path_graph(n=3)},\n",
    "    {'name': 'star', 'graph': nx.star_graph(n=5)},\n",
    "    {'name': 'custom', 'graph': g_custom},\n",
    "    {'name': 'wheel', 'graph': nx.wheel_graph(n=5)},\n",
    "    {'name': 'complete', 'graph': nx.complete_graph(n=5)}\n",
    "]\n",
    "\n",
    "sns.set(rc={'figure.figsize': (15, 4)})\n",
    "fig, ax = plt.subplots(5, 1)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {'name': [ g['name'] for g in graphs],\n",
    "     'graph energy': [ne.get_graph_energy(g['graph']) for g in graphs],\n",
    "     'randic energy': [ne.get_randic_energy(g['graph']) for g in graphs],\n",
    "     'laplacian energy': [ne.get_laplacian_energy(g['graph']) for g in graphs]\n",
    "    }\n",
    ")\n",
    "\n",
    "plt.subplot(151)\n",
    "nx.draw(graphs[0]['graph'], node_color=['r','y','r'])\n",
    "plt.title(graphs[0]['name'])\n",
    "\n",
    "plt.subplot(152)\n",
    "nx.draw(graphs[1]['graph'], node_color=['y','r', 'r', 'r', 'r', 'r'])\n",
    "plt.title(graphs[1]['name'])\n",
    "\n",
    "plt.subplot(153)\n",
    "nx.draw(graphs[2]['graph'], node_color=['y','r','r', 'r', 'r', 'r'])\n",
    "plt.title(graphs[2]['name'])\n",
    "\n",
    "plt.subplot(154)\n",
    "nx.draw(graphs[3]['graph'], node_color=['y','r','r', 'r', 'r'])\n",
    "plt.title(graphs[3]['name'])\n",
    "\n",
    "plt.subplot(155)\n",
    "nx.draw(graphs[4]['graph'], node_color=['y','r','r', 'r', 'r'])\n",
    "plt.title(graphs[4]['name'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "df[['name', 'graph energy', 'randic energy', 'laplacian energy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we start with a star configuration of an egocentric network consisting of an ego and additional $n$ vertices, and we gradually add all remaining edges, until we form a full $K_5$ graph. For each intermediate graph we compute all its energies. We can clearly see that each of matrix energies is measuring a different \"aspect\" of the egocentric network:\n",
    "\n",
    "* randic energy is maximized for topologies very close to the original star-like structure and diminishes as more and more edges are added to the egocentric network\n",
    "* laplacian energy strongly resembles the entropy of adjacency matrix, being maximized half-way between the star structure and the clique structure of the egocentric network\n",
    "* graph energy steadily grows as the density of the egocentric network increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from random import shuffle\n",
    "\n",
    "g = nx.star_graph(n=25)\n",
    "\n",
    "results = []\n",
    "\n",
    "edges = list(combinations(range(1, len(g.nodes)), r=2))\n",
    "\n",
    "# comment if you want to add edges in an ordered way\n",
    "shuffle(edges)\n",
    "\n",
    "for (idx, (i, j)) in enumerate(edges):\n",
    "    results.append((idx, ne.get_graph_energy(g), ne.get_randic_energy(g),\n",
    "                    ne.get_laplacian_energy(g)))\n",
    "\n",
    "    g.add_edge(i, j)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=results,\n",
    "    columns=[\n",
    "        'complexity', 'graph energy', 'randic energy', 'laplacian energy'\n",
    "    ])\n",
    "\n",
    "df['graph energy'] = normalize_df_column(df['graph energy'])\n",
    "df['randic energy'] = normalize_df_column(df['randic energy'])\n",
    "df['laplacian energy'] = normalize_df_column(df['laplacian energy'])\n",
    "\n",
    "dfm = pd.melt(\n",
    "    df,\n",
    "    value_vars=['graph energy', 'randic energy', 'laplacian energy'],\n",
    "    id_vars='complexity')\n",
    "\n",
    "sns.set(rc={'figure.figsize': (12, 8)})\n",
    "sns.lineplot(data=dfm, x='complexity', y='value', hue='variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation of graph/Randić/Laplacian energy and betweenness in artificial networks\n",
    "\n",
    "In this experiment we create several instances of networks generated by two popular models:\n",
    "\n",
    "- Erdos-Renyi random network model\n",
    "- Barabasi-Albert preferential attachment model\n",
    "\n",
    "and for each network we modify its main generative parameter. For each network we collect detailed statistics on every node:\n",
    "\n",
    "- its betweenness,\n",
    "- its Randić energy,\n",
    "- its Laplacian energy,\n",
    "- and its graph energy.\n",
    "\n",
    "We normalize these variables using MinMax scaling to the range of [0-1]. Finally, we group the data by network model and network model parameter used to generate a given network instance, and for each such combination we compute the correlation of \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2976da212aa14dfebde55676337f51da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_nodes = 250\n",
    "\n",
    "results = pd.DataFrame(columns=['node',\n",
    "                                'betweenness',\n",
    "                                'randic_energy',\n",
    "                                'graph_energy',\n",
    "                                'network_model',\n",
    "                                'network_model_param'])\n",
    "\n",
    "# iterate over different parameter settings\n",
    "network_model_params = [p/100 for p in range(1, 10)]\n",
    "\n",
    "# radius of egocentric networks for energy computation\n",
    "radius = 1\n",
    "\n",
    "# sizes of groups for SBM\n",
    "sizes = [50, 50, 150]\n",
    "\n",
    "# intra- and inter-densities of edges between groups in SBM\n",
    "\n",
    "\n",
    "def pa(): return np.random.uniform(0, 0.1)\n",
    "\n",
    "\n",
    "def pb(): return np.random.uniform(0.2, 0.3)\n",
    "\n",
    "\n",
    "for p in tqdm(network_model_params):\n",
    "\n",
    "    probs = np.matrix([[pb(), pa(), pa()],\n",
    "                       [pa(), pb(), pa()],\n",
    "                       [pa(), pa(), pb()]])\n",
    "\n",
    "    # symmetrize the matrix\n",
    "    probs = np.maximum(probs, probs.T)\n",
    "\n",
    "    # generate random and power-law networks with n=500 and p=0.01, 0.02, ..., 0.10\n",
    "    generators = {\n",
    "        'random': nx.erdos_renyi_graph(n=num_nodes, p=p),\n",
    "        'powerlaw': nx.powerlaw_cluster_graph(n=num_nodes, m=2, p=p),\n",
    "        'sbm': nx.stochastic_block_model(sizes=sizes, p=np.array(probs))\n",
    "    }\n",
    "\n",
    "    for generator in generators.keys():\n",
    "\n",
    "        G = generators[generator]\n",
    "\n",
    "        be = nx.betweenness_centrality(G, k=None)\n",
    "        re = ne.randic_centrality(G, radius=radius)\n",
    "        ge = ne.graph_energy_centrality(G, radius=radius)\n",
    "        le = ne.laplacian_centrality(G, radius=radius)\n",
    "\n",
    "        _dict = {\n",
    "            'node': list(G.nodes),\n",
    "            'betweenness': list(be.values()),\n",
    "            'randic_energy': list(re.values()),\n",
    "            'graph_energy': list(ge.values()),\n",
    "            'laplacian_energy': list(le.values()),\n",
    "            'network_model': [generator] * G.number_of_nodes(),\n",
    "            'network_model_param': [p] * G.number_of_nodes()\n",
    "        }\n",
    "\n",
    "        _result = pd.DataFrame.from_dict(_dict)\n",
    "\n",
    "        results = pd.concat([results, _result], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>betweenness</th>\n",
       "      <th>randic_energy</th>\n",
       "      <th>graph_energy</th>\n",
       "      <th>laplacian_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6750.000000</td>\n",
       "      <td>6750.000000</td>\n",
       "      <td>6750.000000</td>\n",
       "      <td>6750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.014029</td>\n",
       "      <td>0.340769</td>\n",
       "      <td>0.146380</td>\n",
       "      <td>0.137020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.036699</td>\n",
       "      <td>0.228959</td>\n",
       "      <td>0.187477</td>\n",
       "      <td>0.175795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.003961</td>\n",
       "      <td>0.120695</td>\n",
       "      <td>0.016222</td>\n",
       "      <td>0.010233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.235416</td>\n",
       "      <td>0.049650</td>\n",
       "      <td>0.056717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.012679</td>\n",
       "      <td>0.570438</td>\n",
       "      <td>0.201089</td>\n",
       "      <td>0.183017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       betweenness  randic_energy  graph_energy  laplacian_energy\n",
       "count  6750.000000    6750.000000   6750.000000       6750.000000\n",
       "mean      0.014029       0.340769      0.146380          0.137020\n",
       "std       0.036699       0.228959      0.187477          0.175795\n",
       "min       0.000000       0.000000      0.000000          0.000000\n",
       "25%       0.003961       0.120695      0.016222          0.010233\n",
       "50%       0.007575       0.235416      0.049650          0.056717\n",
       "75%       0.012679       0.570438      0.201089          0.183017\n",
       "max       1.000000       1.000000      1.000000          1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize columns to the range [0,1]\n",
    "\n",
    "results.betweenness = normalize_df_column(results.betweenness)\n",
    "results.randic_energy = normalize_df_column(results.randic_energy)\n",
    "results.graph_energy = normalize_df_column(results.graph_energy)\n",
    "results.laplacian_energy = normalize_df_column(results.laplacian_energy)\n",
    "\n",
    "results[['betweenness','randic_energy','graph_energy','laplacian_energy']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the correlation between betweenness and randić energy for different models?\n",
    "_results = results.groupby(\n",
    "    ['network_model_param',\n",
    "     'network_model'])[['betweenness',\n",
    "                        'randic_energy', \n",
    "                        'graph_energy',\n",
    "                        'laplacian_energy']].corr().reset_index()\n",
    "\n",
    "# extract correlations for the two models\n",
    "powerlaw_idx = _results['network_model'] == 'powerlaw'\n",
    "random_idx = _results['network_model'] == 'random'\n",
    "sbm_idx = _results['network_model'] == 'sbm'\n",
    "\n",
    "powerlaw_corr = _results[powerlaw_idx]['betweenness'].tolist()\n",
    "random_corr = _results[random_idx]['betweenness'].tolist()\n",
    "sbm_corr = _results[sbm_idx]['betweenness'].tolist()\n",
    "\n",
    "# get additional columns with network model parameter and type of energy\n",
    "network_model_param = _results[random_idx]['network_model_param'].tolist()\n",
    "energy_idx = _results[random_idx]['level_2'].tolist()\n",
    "\n",
    "correlations = pd.DataFrame({'p': network_model_param, \n",
    "                             'energy': energy_idx,\n",
    "                             'powerlaw': powerlaw_corr, \n",
    "                             'random': random_corr,\n",
    "                             'sbm': sbm_corr})\n",
    "\n",
    "# melt the DataFrame to a format more suitable for drawing\n",
    "correlations_mlt = pd.melt(correlations[correlations['energy'] != 'betweenness'], \n",
    "                id_vars=['p','energy'], \n",
    "                value_vars=['powerlaw','random','sbm'], \n",
    "                var_name='network_model', \n",
    "                value_name='correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(correlations_mlt, col='energy', hue='network_model', height=8)\n",
    "g.map(sns.lineplot, 'p', 'correlation')\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of graph energies centrality\n",
    "\n",
    "We visualize Randić, Laplacian and graph energy for the well-known Zachary karate club network. The energy of each vertex is denoted by its color and size. As can be seen, the correlation between these centralities is very high and they all provide similar information. Also, one can see that these centralities have strong preference to nodes that are either central to their cluster, or lying in between clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax = MinMaxScaler()\n",
    "\n",
    "norm = lambda lst: minmax.fit_transform(np.asarray(lst, dtype=np.float32).\n",
    "                                        reshape(-1,1)).reshape(-1).tolist()\n",
    "\n",
    "g = nx.karate_club_graph()\n",
    "\n",
    "re = list(ne.randic_centrality(g).values())\n",
    "re = norm(re)\n",
    "\n",
    "le = list(ne.laplacian_centrality(g).values())\n",
    "le = norm(le)\n",
    "\n",
    "ge = list(ne.graph_energy_centrality(g).values())\n",
    "ge = norm(ge)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "\n",
    "fig, ax = plt.subplots(3,1)\n",
    "\n",
    "plt.subplot(131)\n",
    "options = { \n",
    "    'node_color': [d * 1 for d in ge], \n",
    "    'node_size': [d * 1000 for d in ge], \n",
    "    'cmap': plt.cm.Greens,\n",
    "    'edge_color': 'gray' \n",
    "}\n",
    "nx.draw_kamada_kawai(g, **options)\n",
    "plt.title('Graph energy')\n",
    "\n",
    "plt.subplot(132)\n",
    "options = { \n",
    "    'node_color': [d * 1 for d in le], \n",
    "    'node_size': [d * 1000 for d in le], \n",
    "    'cmap': plt.cm.Oranges,\n",
    "    'edge_color': 'gray' \n",
    "}\n",
    "nx.draw_kamada_kawai(g, **options)\n",
    "plt.title('Laplacian energy')\n",
    "\n",
    "plt.subplot(133)\n",
    "options = { \n",
    "    'node_color': [d * 1 for d in re], \n",
    "    'node_size': [d * 1000 for d in re], \n",
    "    'cmap': plt.cm.Purples,\n",
    "    'edge_color': 'gray'\n",
    "}\n",
    "nx.draw_kamada_kawai(g, **options)\n",
    "plt.title('Randić energy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression modeling in synthetic networks\n",
    "\n",
    "As the next step we fit regression models and compute their accuracy in terms of\n",
    "\n",
    "  * Pearson, Spearman, and Kendall correlations\n",
    "  * mean absolute error\n",
    "  * mean squarred error\n",
    "  \n",
    "In the experiment we fit various regressors:\n",
    "\n",
    "- simple linear model\n",
    "- random forest regressor\n",
    "- gradient boosting regressor\n",
    "\n",
    "We collect the data from generative network models, and for each vertex we note its betweenness and its energies. Then, we fit these three regressors for networks generated for a particular value of the generative attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau, rankdata\n",
    "\n",
    "regression_models = {\n",
    "    'linear model': LinearRegression(), \n",
    "    'random forest': RandomForestRegressor(), \n",
    "    'gradient boosting': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "prediction_results = []\n",
    "\n",
    "for network_model in results['network_model'].unique():\n",
    "    for network_model_param in network_model_params:\n",
    "        \n",
    "        model_idx = results['network_model'] == network_model\n",
    "        param_idx = results['network_model_param'] == network_model_param\n",
    "        \n",
    "        df = results[ model_idx & param_idx]\n",
    "        \n",
    "        y = df['betweenness'].values\n",
    "        X = df[['randic_energy','graph_energy','laplacian_energy']].values\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "        \n",
    "        for regression_model in regression_models:\n",
    "            \n",
    "            l_model = regression_models[regression_model]\n",
    "            \n",
    "            l_model.fit(X=X_train, y=y_train)\n",
    "            y_pred = l_model.predict(X_test)\n",
    "\n",
    "            y_ranked = rankdata(y_test, method='ordinal') \n",
    "            y_pred_ranked = rankdata(y_pred, method='ordinal')\n",
    "\n",
    "            _dict = {\n",
    "                'regression_model': regression_model,\n",
    "                'network_model': network_model,\n",
    "                'network_model_param': network_model_param,\n",
    "                'mae': mean_absolute_error(y_true=y_test, y_pred=y_pred),\n",
    "                'mse': mean_squared_error(y_true=y_test, y_pred=y_pred),\n",
    "                'r2': r2_score(y_test, y_pred),\n",
    "                'pearson': pearsonr(y_test, y_pred)[0],\n",
    "                'spearman': spearmanr(y_test, y_pred, axis=0, nan_policy='propagate')[0],\n",
    "                'kendall': kendalltau(y_ranked, y_pred_ranked, initial_lexsort=None, nan_policy='propagate')[0]\n",
    "            }\n",
    "\n",
    "            prediction_results.append(_dict)\n",
    "\n",
    "# convert the list of dicts into a DataFrame\n",
    "prediction_results = pd.DataFrame(prediction_results, \n",
    "             columns=['regression_model', \n",
    "                      'network_model',\n",
    "                      'network_model_param', \n",
    "                      'mae', \n",
    "                      'mse', \n",
    "                      'r2', \n",
    "                      'pearson', \n",
    "                      'spearman', \n",
    "                      'kendall'])\n",
    "\n",
    "# melt DataFrame to transform it into tidy format\n",
    "prediction_results_mlt = pd.melt(prediction_results,\n",
    "                             id_vars=['regression_model', 'network_model','network_model_param'], \n",
    "                             var_name='measure',\n",
    "                             value_name='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the relationship between betweenness and energies in synthetic networks\n",
    "\n",
    "The following figures show the linear model predicting vertex betweenness based on graph energy, Randić energy, and Laplacian energy for random and powerlaw networks for a fixed value of the generative parameter. The value of the parameter is drawn randomly from the entire domain of the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network_model = 'random'\n",
    "network_model_param = np.random.choice(network_model_params)\n",
    "\n",
    "sns.jointplot(x='randic_energy',\n",
    "              y='betweenness', \n",
    "              data=results[(results['network_model'] == network_model) \n",
    "                           & (results['network_model_param'] == network_model_param)], \n",
    "              kind='reg', \n",
    "              color=\"xkcd:sky blue\")\n",
    "\n",
    "sns.jointplot(x='graph_energy', \n",
    "              y='betweenness',\n",
    "              data=results[(results['network_model'] == network_model) \n",
    "                           & (results['network_model_param'] == network_model_param)], \n",
    "              kind=\"reg\", \n",
    "              color=\"xkcd:strawberry\")\n",
    "\n",
    "sns.jointplot(x='laplacian_energy', \n",
    "              y='betweenness',\n",
    "              data=results[(results['network_model'] == network_model) \n",
    "                           & (results['network_model_param'] == network_model_param)], \n",
    "              kind=\"reg\", \n",
    "              color=\"xkcd:blue gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_model = 'powerlaw'\n",
    "network_model_param = np.random.choice(network_model_params)\n",
    "\n",
    "sns.jointplot(x='randic_energy', \n",
    "              y='betweenness', \n",
    "              data=results[(results['network_model'] == network_model)\n",
    "                          & (results['network_model_param'] == network_model_param)], \n",
    "              kind='reg', \n",
    "              color=\"xkcd:medium blue\")\n",
    "\n",
    "sns.jointplot(x='graph_energy', \n",
    "              y='betweenness',\n",
    "              data=results[(results['network_model'] == network_model)\n",
    "                          & (results['network_model_param'] == network_model_param)], \n",
    "              kind=\"reg\", \n",
    "              color=\"xkcd:pumpkin orange\")\n",
    "\n",
    "sns.jointplot(x='laplacian_energy', \n",
    "              y='betweenness',\n",
    "              data=results[(results['network_model'] == network_model)\n",
    "                          & (results['network_model_param'] == network_model_param)], \n",
    "              kind=\"reg\", \n",
    "              color=\"xkcd:moss green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we present correlation measures (Pearson, Spearman, Kendall) which describe the relationship of betweenness and vertex energies (Randic, Laplacian and Graph). We randomly select the value of the network generator parameter and repeat the correlation computation, averaging the results over 1000 runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "number_of_runs = 1000\n",
    "\n",
    "\n",
    "for network_model in results.network_model.unique():\n",
    "    for run in tqdm(range(number_of_runs)):\n",
    "        \n",
    "        network_model_param = np.random.choice(network_model_params)\n",
    "\n",
    "        network_model_idx = results['network_model'] == network_model\n",
    "        network_model_param_idx = results['network_model_param'] == network_model_param\n",
    "\n",
    "        for method in ['kendall','spearman','pearson']:\n",
    "\n",
    "            _corr = results[network_model_idx & network_model_param_idx][\n",
    "                ['betweenness',\n",
    "                 'randic_energy',\n",
    "                 'graph_energy',\n",
    "                 'laplacian_energy']].corr(method=method)\n",
    "            \n",
    "            result.append((network_model, \n",
    "                           network_model_param, \n",
    "                           method, \n",
    "                           _corr.betweenness['randic_energy'], \n",
    "                           _corr.betweenness['graph_energy'],\n",
    "                           _corr.betweenness['laplacian_energy']))\n",
    "        \n",
    "correlations = pd.DataFrame(result, \n",
    "                            columns=['network_model', \n",
    "                                     'network_model_param',\n",
    "                                     'method', \n",
    "                                     'BRC', \n",
    "                                     'BGC',\n",
    "                                     'BLC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations[['network_model','method','BRC','BGC','BLC']].groupby(['network_model','method']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt DataFrame to transform it into tidy format\n",
    "correlations_mlt = pd.melt(correlations,\n",
    "                             id_vars=['network_model','network_model_param', 'method'], \n",
    "                             var_name='measure',\n",
    "                             value_name='correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_defaults()\n",
    "\n",
    "g = sns.FacetGrid(correlations_mlt, col='network_model', row='measure', hue='method', height=5, sharey=False)\n",
    "g.map(sns.lineplot, 'network_model_param', 'correlation')\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical networks\n",
    "\n",
    "In this experiment we are trying to verify if the relationship between vertex energies and vertex betweenness holds also in empirical networks. We download a set of networks from the Koblenz network repository and compute the basic statistics of these networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import wget\n",
    "import tarfile\n",
    "import os\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_avalilable_datasets_konect():\n",
    "    base_url = \"http://konect.uni-koblenz.de/downloads/\"\n",
    "    response = requests.get(base_url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"An error occurred while getting data.\")\n",
    "    else:\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html, \"html5lib\")\n",
    "        \n",
    "        table_html = soup.find(id='sort1')\n",
    "        \n",
    "        thead_html = table_html.find('thead')\n",
    "        tbody_html = table_html.find('tbody')\n",
    "         \n",
    "        column_names=[row.text for row in thead_html.findAll('td')]\n",
    "        rows = tbody_html.findAll('tr')\n",
    "        values=[[cell.get('href') for cell in value('a') if 'tsv' in cell.get('href')] for value in rows]\n",
    "        return [val[0].replace('.tar.bz2','').replace('tsv/','') for val in values]\n",
    "        \n",
    "def download_tsv_dataset_konect(network_name):\n",
    "    assert (network_name in read_avalilable_datasets_konect()),\"No network named: '\"+network_name+\"' found in Konect!\"\n",
    "    \n",
    "    tsv_file = 'http://konect.uni-koblenz.de/downloads/tsv/'+network_name+'.tar.bz2'\n",
    "    output_file=network_name+'.tar.bz2'\n",
    "    file_name = wget.download(tsv_file, out=output_file)\n",
    "    if os.path.exists(output_file):\n",
    "        shutil.move(file_name,output_file)\n",
    "    \n",
    "    return output_file\n",
    "    \n",
    "def unpack_tar_bz2_file(file_name):\n",
    "    tar = tarfile.open(\"./\"+file_name, \"r:bz2\")\n",
    "    output_dir=\"./network_\"+file_name.replace('.tar.bz2','')+\"/\"\n",
    "    tar.extractall(output_dir)\n",
    "    tar.close()\n",
    "    return output_dir\n",
    "\n",
    "def build_network_from_out_konect(network_name):\n",
    "    file_name=download_tsv_dataset_konect(network_name=network_name)\n",
    "    output_dir=unpack_tar_bz2_file(file_name)+network_name+\"/\"\n",
    "    files = [file for file in os.listdir(output_dir) if os.path.isfile(os.path.join(output_dir, file))]\n",
    "    out_file = [file for file in files if 'out.' in file]\n",
    "    assert (len(out_file)>0), 'No out. file in the directory.'\n",
    "    \n",
    "    #building network\n",
    "    G=nx.read_adjlist(output_dir+out_file[0], comments='%')\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks_names=[\n",
    " 'moreno_beach',\n",
    " 'moreno_bison',\n",
    " 'moreno_blogs',\n",
    " 'moreno_cattle',\n",
    " 'moreno_crime',\n",
    " 'moreno_health',\n",
    " 'moreno_highschool',\n",
    " 'moreno_innovation',\n",
    " 'moreno_kangaroo',\n",
    " 'moreno_lesmis',\n",
    " 'moreno_mac',\n",
    " 'moreno_names',\n",
    " 'moreno_oz',\n",
    " 'moreno_propro',\n",
    " 'moreno_rhesus',\n",
    " 'moreno_sampson',\n",
    " 'moreno_seventh',\n",
    " 'moreno_sheep',\n",
    " 'moreno_taro',\n",
    " 'moreno_train',\n",
    " 'moreno_vdb',\n",
    " 'moreno_zebra',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks=[]\n",
    "\n",
    "for network_name in tqdm(networks_names):\n",
    "    networks.append(build_network_from_out_konect(network_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute basic network statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_stats = []\n",
    "\n",
    "for (name, network) in zip(networks_names, networks):\n",
    "    network_stats.append((name, \n",
    "                          network.number_of_nodes(), \n",
    "                          network.number_of_edges(),\n",
    "                          np.round(network.number_of_edges()/network.number_of_nodes(), 2)))\n",
    "    \n",
    "network_statistics_df = pd.DataFrame(network_stats, columns=['network name', \n",
    "                                          'number of vertices', \n",
    "                                          'number of edges', \n",
    "                                          'average degree'])\n",
    "\n",
    "# print(network_statistics_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_statistics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the density ratio where our method beats SOTA\n",
    "\n",
    "Our initial analysis points to a certain area of the (#vertices, avg.degree) parameter space, where our method of betweenness estimation should perform better than the best currently known exact algorithm of betweenness estimation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(1, network_statistics_df['number of vertices'].max())\n",
    "y1 = np.power(x * np.log(x), 1 / 3)\n",
    "y2 = np.power(x, 2 / 3)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'num vertices': x,\n",
    "    'best limit': y1,\n",
    "    'naive limit': y2\n",
    "}).melt(\n",
    "    id_vars=['num vertices'], var_name='average degree limit')\n",
    "\n",
    "sns.set(rc={'figure.figsize': (11.7, 8.27)})\n",
    "\n",
    "figure = sns.lineplot(\n",
    "    data=df, x='num vertices', y='value', hue='average degree limit')\n",
    "\n",
    "plt.xlabel('number of vertices')\n",
    "plt.ylabel('average vertex degree')\n",
    "\n",
    "ax = sns.regplot(\n",
    "    x=network_statistics_df['number of vertices'],\n",
    "    y=network_statistics_df['average degree'],\n",
    "    scatter=True,\n",
    "    fit_reg=False,\n",
    "    marker='o',\n",
    "    scatter_kws={\"s\": 50})\n",
    "# the \"s\" key in `scatter_kws` modifies the size of the marker\n",
    "\n",
    "network_data_labels = network_statistics_df[\n",
    "    network_statistics_df['number of vertices'] > 200]\n",
    "\n",
    "[\n",
    "    ax.text(p[0] + 2, p[1] + 3, p[2])\n",
    "    for p in zip(network_data_labels['number of vertices'],\n",
    "                 network_data_labels['average degree'],\n",
    "                 network_data_labels['network name'])\n",
    "]\n",
    "\n",
    "plt.show(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the correlation of betweenness and egocentric energies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we calculate betweenness and energy measures for each vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_measures = pd.DataFrame(columns=['node', 'value_type','value','network'])\n",
    "\n",
    "for i in tqdm(range(len(networks))):\n",
    "    G = networks[i]\n",
    "    \n",
    "    be = nx.betweenness_centrality(G, k=None)\n",
    "    tmp_df = pd.DataFrame({'node': [i[0] for i in be.items()],\n",
    "                         'value_type': ['betweenness' for i in be.items()],\n",
    "                         'value': [i[1] for i in be.items()],\n",
    "                         'network': [networks_names[i] for j in be.items()]\n",
    "                        })\n",
    "    tmp_df['value'] = normalize_df_column(tmp_df['value'])\n",
    "    real_data_measures = pd.concat([real_data_measures,tmp_df])\n",
    "        \n",
    "        \n",
    "    re = ne.randic_centrality(G)\n",
    "    tmp_df = pd.DataFrame({'node': [i[0] for i in re.items()],\n",
    "                         'value_type': ['randic' for i in re.items()],\n",
    "                         'value': [i[1] for i in re.items()],\n",
    "                         'network': [networks_names[i] for j in be.items()]\n",
    "                        })\n",
    "    tmp_df['value'] = normalize_df_column(tmp_df['value'])\n",
    "    real_data_measures = pd.concat([real_data_measures, tmp_df])\n",
    "\n",
    "    ge = ne.graph_energy_centrality(G)\n",
    "    tmp_df = pd.DataFrame({'node': [i[0] for i in ge.items()],\n",
    "                         'value_type': ['graph' for i in ge.items()],\n",
    "                         'value': [i[1] for i in ge.items()],\n",
    "                         'network': [networks_names[i] for j in be.items()]\n",
    "                        })\n",
    "    tmp_df['value'] = normalize_df_column(tmp_df['value'])\n",
    "    real_data_measures = pd.concat([real_data_measures, tmp_df])\n",
    "    \n",
    "    le = ne.laplacian_centrality(G)\n",
    "    tmp_df = pd.DataFrame({'node': [i[0] for i in le.items()],\n",
    "                         'value_type': ['laplacian' for i in le.items()],\n",
    "                         'value': [i[1] for i in le.items()],\n",
    "                         'network': [networks_names[i] for j in be.items()]\n",
    "                        })\n",
    "    tmp_df['value'] = normalize_df_column(tmp_df['value'])\n",
    "    real_data_measures = pd.concat([real_data_measures, tmp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_measures.to_pickle('./real_networks_calulated_betweenness_and_energy.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_results(net, y, y_pred):\n",
    "    \n",
    "    real_prediction_results = pd.DataFrame(columns=['network', 'error_type', 'error_value'])\n",
    "    \n",
    "    mae = sklearn.metrics.mean_absolute_error(y_true=y, y_pred=y_pred)\n",
    "    tmp_df = pd.DataFrame({'network': [net],\n",
    "                         'error_type': ['MAE'], \n",
    "                         'error_value': [mae]\n",
    "                        })\n",
    "    real_prediction_results = pd.concat([real_prediction_results, tmp_df])\n",
    "\n",
    "    mse = sklearn.metrics.mean_squared_error(y_true=y, y_pred=y_pred)\n",
    "    tmp_df = pd.DataFrame({'network': [net],\n",
    "                         'error_type': ['MSE'], \n",
    "                         'error_value': [mse]\n",
    "                        })\n",
    "    real_prediction_results = pd.concat([real_prediction_results, tmp_df])\n",
    "\n",
    "    pearson,_ = scipy.stats.pearsonr(x=y,y=y_pred)\n",
    "    tmp_df = pd.DataFrame({'network': [net],\n",
    "                         'error_type': ['pearson'], \n",
    "                         'error_value': [pearson]\n",
    "                        })\n",
    "    real_prediction_results = pd.concat([real_prediction_results, tmp_df])\n",
    "\n",
    "    spearman,_ = scipy.stats.spearmanr(a=y,b=y_pred, axis=0, nan_policy='propagate')\n",
    "    tmp_df = pd.DataFrame({'network': [net],\n",
    "                         'error_type': ['spearman'], \n",
    "                         'error_value': [spearman]\n",
    "                        })\n",
    "    real_prediction_results = pd.concat([real_prediction_results, tmp_df])\n",
    "\n",
    "\n",
    "    y_ranked = scipy.stats.rankdata(y, method='ordinal') #może metoda average\n",
    "    y_pred_ranked = scipy.stats.rankdata(y_pred, method='ordinal')\n",
    "\n",
    "    kendall,_ = scipy.stats.kendalltau(x=y_ranked,y=y_pred_ranked, initial_lexsort=None, nan_policy='propagate')\n",
    "    tmp_df = pd.DataFrame({'network': [net],\n",
    "                         'error_type': ['kendall'], \n",
    "                         'error_value': [kendall]\n",
    "                        })\n",
    "    real_prediction_results = pd.concat([real_prediction_results, tmp_df])    \n",
    "    \n",
    "    return real_prediction_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "real_prediction_results = pd.DataFrame(columns=['network', 'error_type', 'error_value'])\n",
    "models = []\n",
    "\n",
    "real_data_measures = pd.read_pickle('./real_networks_calulated_betweenness_and_energy.pickle')\n",
    "\n",
    "\n",
    "for net in tqdm(real_data_measures['network'].unique()):\n",
    "\n",
    "        l_model = KNeighborsRegressor(n_neighbors=10, weights='distance')\n",
    "        l_model = RandomForestRegressor()\n",
    "    \n",
    "        y = real_data_measures[(real_data_measures['network']==net) & \n",
    "                  (real_data_measures['value_type']=='betweenness')\n",
    "                 ]['value'].values\n",
    "\n",
    "        X = real_data_measures[(real_data_measures['network']==net) & \n",
    "                  (real_data_measures['value_type']=='graph')\n",
    "                 ]['value'].values\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        l_model.fit(X_train.reshape(-1, 1), y_train)\n",
    "\n",
    "        models.append(l_model)\n",
    "        \n",
    "        y_pred=l_model.predict(X_test.reshape(-1, 1))\n",
    "        \n",
    "        real_prediction_results=pd.concat([real_prediction_results,evaluate_results(net,y_test,y_pred)])\n",
    "        \n",
    "        \n",
    "real_prediction_results.to_pickle('./real_prediction_results_errors.pickle')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "real_prediction_results=pd.read_pickle('./real_prediction_results_errors.pickle') \n",
    "\n",
    "f, axs = plt.subplots(5, 1, figsize=(10, 28), sharex=True, sharey=False)\n",
    "\n",
    "for error_type, ax in zip(real_prediction_results['error_type'].unique(),axs):\n",
    "    \n",
    "    x = real_prediction_results[real_prediction_results['error_type']==error_type]['network'].values\n",
    "    y = real_prediction_results[real_prediction_results['error_type']==error_type]['error_value'].values\n",
    "    \n",
    "    colors = {'MAE': 'xkcd:salmon',\n",
    "              'MSE': 'xkcd:pea green', \n",
    "              'pearson': 'xkcd:sky blue', \n",
    "              'spearman': 'xkcd:goldenrod', \n",
    "              'kendall': 'xkcd:moss green'}\n",
    "    \n",
    "    plt.ylim([0,1])    \n",
    "    ax.set_xticklabels(x,rotation='vertical')\n",
    "    ax.set_title(error_type, fontsize=18)\n",
    "    ax.set(xlabel='Network', ylabel='Value')\n",
    "    sns.barplot(x, y, ax=ax, color=colors[error_type])\n",
    "    \n",
    "sns.despine(bottom=True)\n",
    "plt.tight_layout(h_pad=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.pivot_table(real_prediction_results.round(2), \n",
    "                    index='network', \n",
    "                    columns='error_type', \n",
    "                    values='error_value').rename_axis(None, axis=1)\n",
    "# print(df.to_latex())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning\n",
    "\n",
    "In this experiment we check if it is possible to train the regression model on one network and then transfer the same model to other networks. In other words, if the relationship between vertex betweenness and vertex energy is universal, such transfer learning should be possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_measures = pd.read_pickle('./real_networks_calulated_betweenness_and_energy.pickle')\n",
    "\n",
    "transfer_real_prediction_results = pd.DataFrame(columns=['network', 'error_type', 'error_value', 'source_network'])\n",
    "\n",
    "raw_results = pd.DataFrame(columns=['network', 'source_network', 'y', 'y_pred'])\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(models))):\n",
    "    for net in (real_data_measures['network'].unique()):\n",
    "        y=real_data_measures[(real_data_measures['network']==net) & \n",
    "                  (real_data_measures['value_type']=='betweenness')\n",
    "                 ]['value'].values\n",
    "\n",
    "        X=real_data_measures[(real_data_measures['network']==net) & \n",
    "                  (real_data_measures['value_type']=='graph')\n",
    "                 ]['value'].values\n",
    "        \n",
    "        y_pred = models[i].predict(X.reshape(-1, 1))\n",
    "        \n",
    "        eval_res = evaluate_results(net,y,y_pred)\n",
    "        eval_res['source_network'] = networks_names[i]\n",
    "        \n",
    "        raw_results = pd.concat([raw_results, pd.DataFrame.from_dict({'network': net, \n",
    "                                                                      'source_network': networks_names[i], \n",
    "                                                                      'y': y, \n",
    "                                                                      'y_pred':y_pred})])\n",
    "        \n",
    "        transfer_real_prediction_results = pd.concat([transfer_real_prediction_results,eval_res])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets draw a heatmap representing betweenness estimation errors and rank correlations for empirical networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette('Oranges')\n",
    "sns.set_context(\"notebook\", font_scale=1.8)\n",
    "\n",
    "for error_type in ['MAE', 'MSE']:\n",
    "    \n",
    "    error_idx = transfer_real_prediction_results['error_type']==error_type\n",
    "    \n",
    "    x = transfer_real_prediction_results[error_idx]['network'].unique()\n",
    "    y = transfer_real_prediction_results[error_idx]['network'].unique()\n",
    "\n",
    "    val = np.array(transfer_real_prediction_results[error_idx]['error_value'])\n",
    "    val = val.reshape(len(x),len(y))\n",
    "\n",
    "    plt.figure(figsize=(50,50))\n",
    "    plt.title(error_type)\n",
    "    \n",
    "    to_draw=transfer_real_prediction_results[transfer_real_prediction_results['error_type']==error_type]\n",
    "    \n",
    "    ax = sns.heatmap(to_draw[['error_value', \n",
    "                              'source_network', \n",
    "                              'network']].pivot('source_network',\n",
    "                                                'network',\n",
    "                                                'error_value'), \n",
    "                     linewidth=0.5,\n",
    "                     annot=True,\n",
    "                     cmap='Oranges')\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for error_type in ['pearson', 'spearman', 'kendall']:\n",
    "    \n",
    "    error_idx = transfer_real_prediction_results['error_type']==error_type\n",
    "    \n",
    "    x = transfer_real_prediction_results[error_idx]['network'].unique()\n",
    "    y = transfer_real_prediction_results[error_idx]['network'].unique()\n",
    "\n",
    "    val = np.array(transfer_real_prediction_results[error_idx]['error_value'])\n",
    "    val = val.reshape(len(x),len(y))\n",
    "\n",
    "    plt.figure(figsize=(50,50))\n",
    "    plt.title(error_type)\n",
    "    \n",
    "    to_draw=transfer_real_prediction_results[error_idx]\n",
    "    \n",
    "    ax = sns.heatmap(to_draw[['error_value', \n",
    "                              'source_network', \n",
    "                              'network']].pivot('source_network',\n",
    "                                                'network',\n",
    "                                                'error_value'), \n",
    "                     linewidth=0.5,\n",
    "                     annot=True,\n",
    "                     cmap='Oranges')\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
